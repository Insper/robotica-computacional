{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura de Imagem e Webcam\n",
    "\n",
    "# 1. Leitura de Imagens com OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version : 4.5.3 \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print (\"OpenCV Version : %s \" % cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"leitura\"></div>\n",
    "\n",
    "## 1.1 Leitura e Exibição de Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `cv2.imread` na célula abaixo fará a leitura de um arquivo de imagem e armazenará em uma variável, `grid`.\n",
    "\n",
    "Observe atentamente a imagem abaixo, que é a imagem [original](img/img9x9_aumentada.png).\n",
    "\n",
    "![](img/img9x9_aumentada.png)\n",
    "\n",
    "Nota-se que temos uma grade de 9x9, onde a célula **superior esquerda** é da cor **vermelha** e a **superior direita** é da cor **azul**.\n",
    "\n",
    "Agora vamos abrir a imagem com o OpenCV utilizando a função `cv2.imread` e armazenar em uma variável chamada `grid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = cv2.imread(\"img/img9x9_aumentada.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar a imagem com a função `cv2.imshow`.\n",
    "\n",
    "Quando mostramos uma imagem com o OpenCV, não podemos esquecer de chamar `cv2.waitKey()` para segurar a imagem, e `cv2.destroyAllWindows()` para fechar as janelas antes de sair da célula de código.\n",
    "\n",
    "!!! Avisos \"Aviso\"\n",
    "    *  A célula abaixo vai abrir uma janela com a imagem. Esta janela pode estar escondida atrás desta janela do navegador.\n",
    "\n",
    "    * Se você fechar a janela, o programa vai travar. Para continuar a execução, `aperte qualquer tecla enquanto a janela estiver ativa`.\n",
    "\n",
    "    * Se já fechou a janela, você pode reiniciar o kernel para continuar a execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Imagem BGR\", grid)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historicamente, a ordem dos sub-pixels das imagens usadas pelo OpenCV é invertida: em vez de `RGB` é `BGR`.\n",
    "\n",
    "Podemos fazer a conversão de `BGR` para `RGB` com a função `cv2.cvtColor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rgb = cv2.cvtColor(grid, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"Imagem BGR\", grid_rgb)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a célula superior esquerda agora é azul e a superior direita é vermelha. Isso acontece porque o **OpenCV SEMPRE entende que a imagem está no formato BGR, e não RGB.**\n",
    "\n",
    "Então quando fizemos a operação `cv2.cvtColor(grid, cv2.COLOR_BGR2RGB)`, não estamos **OBJETIVAMENTE** convertendo de BGR para RGB, mas apenas trocando a ordem dos canais de forma **SUBJETIVA**. Isso porque não existe um identificador para o formato RGB ou BGR, mas apenas uma **convenção** na hora de trabalhar com a imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Imagens como matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No OpenCV as imagens são matrizes do numpy. Vamos carrgar uma versão pequena da imagem anterior, com apenas 9 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "mini_grid = cv2.imread(\"img/img9x9.png\")\n",
    "\n",
    "print(mini_grid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos: `mini_grid.shape = (3,3,3)`.\n",
    "\n",
    "Isso significa que a imagem é uma matriz com, respectivamente, 3 linhas, 3 colunas e 3 canais de cor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  5,   5, 255],\n",
       "        [255, 255, 255],\n",
       "        [255,   1,   1]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [  1, 255,   1],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255,   2],\n",
       "        [ 21, 255, 255],\n",
       "        [255,   1, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o *tipo* 'uint8'  quer dizer *unsigned int de 8 bits*. Ou seja, é capaz de representar entre $0$ e $2^{8}-1=255$\n",
    "\n",
    "Esta informação é importante quando manipularmos os bits da imagem. É preciso ter certeza de que não vai ocorrer *overflow* - atribuir valores que o tipo não suporte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Transposta de uma matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos especificar na transposta a ordem em que esperamos que as dimensões da imagem original apareçam. O padrão da OpenCV para a ordem das dimensões é `0=linhas`,  `1=colunas` e `2=componentes de cor`. O que queremos é uma transposta de linhas e colunas, portanto deve ficar como abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = grid.transpose((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Transposta\", trans)\n",
    "cv2.imshow(\"Original\", grid)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a imagem acima teve linhas e colunas transpostas.\n",
    "\n",
    "Agora, vamos estudar uma imagem de uma [arara](img/arara.jpg), primeiramente vamos ler a imagem e exibi-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arara = cv2.imread(\"img/arara.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo `shape` traz as dimensões da matriz.\n",
    "\n",
    "Antes de executar o comando, observe os eixos da imagem abaixo. \n",
    "\n",
    "**Pergunta:** A imagem tem mais linhas ou mais colunas?\n",
    "\n",
    "**Pergunta:** Quantos canais de cor tem a imagem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Arara\", arara)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a imagem tem 3 canais de cor, o que é esperado para uma imagem colorida.\n",
    "A imagem é mais larga do que alta, portanto tem mais colunas do que linhas.\n",
    "\n",
    "Como podemos ver pelo `shape`, da imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 500, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arara.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos transpor também a imagem da arara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arara_transposta = arara.transpose((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 500, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arara.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 333, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arara_transposta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Transposta\", arara_transposta)\n",
    "cv2.imshow(\"Original\", arara)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Separando os canais da imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma imagem é simplesmente uma matriz de pixels. Uma imagem colorida são três matrizes de pixels, \"empilhadas\" uma sobre a outra.\n",
    "\n",
    "O OpenCV permite gerenciar os canais de cor usando `cv2.split()`, para separar os canais, e `cv2.merge()` para juntar os canais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arara.shape (333, 500, 3)\n",
      "arara_b.shape (333, 500)\n",
      "arara_g.shape (333, 500)\n",
      "arara_r.shape (333, 500)\n"
     ]
    }
   ],
   "source": [
    "arara_b, arara_g, arara_r = cv2.split(arara)\n",
    "print('arara.shape', arara.shape)\n",
    "print('arara_b.shape', arara_b.shape)\n",
    "print('arara_g.shape', arara_g.shape)\n",
    "print('arara_r.shape', arara_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as imagens são matrizes do numpy, podemos acessar os canais diretamente usando os índices.\n",
    "\n",
    "Por exemplo, para acessar o canal vermelho, usamos `img[:,:,2]`. O `:` significa \"todos os elementos da dimensão\". Ou seja, estamos acessando todos os elementos das dimensões 0 e 1, e o elemento 2 da dimensão 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arara_b.shape (333, 500)\n",
      "arara_g.shape (333, 500)\n",
      "arara_r.shape (333, 500)\n"
     ]
    }
   ],
   "source": [
    "print('arara_b.shape', arara[:,:,0].shape)\n",
    "print('arara_g.shape', arara[:,:,1].shape)\n",
    "print('arara_r.shape', arara[:,:,2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando os canais separadamente, podemos ver que o canal vermelho é o que tem mais informação, e o canal azul é o que tem menos informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Canal Vermelho\", arara_r)\n",
    "cv2.imshow(\"Canal Verde\", arara_g)\n",
    "cv2.imshow(\"Canal Azul\", arara_b)\n",
    "cv2.imshow(\"Original\", arara)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também voltar à imagem original combinando os canais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arara_rgb_original = cv2.merge([arara_r, arara_g, arara_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original\", arara_rgb_original)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Usando webcam\n",
    "\n",
    "No curso, vamos trabalhar com sequências de imagens, que podem ser obtidas de câmeras ou de arquivos de vídeo.\n",
    "\n",
    "Por exemplo, podemos usar a webcam do computador para capturar imagens e processá-las.\n",
    "\n",
    "Para isso, usamos a função `cv2.VideoCapture(0)`, que abre o dispositivo de vídeo de índice 0 (normalmente a webcam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0) # Tente vários IDs para descobrir qual é em sua webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "t.sleep(5) # Espera a webcam ficar pronta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `cap.read()` retorna um par de valores, sendo o primeiro o uma **flag** indicando se a leitura foi bem sucedida e o segundo a **imagem** lida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val = True\n",
      "image.shape = (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "val, image = webcam.read()\n",
    "print(f'val = {val}')\n",
    "print(f'image.shape = {image.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam.release() # fecha a webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"webcam\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também usar a janela do OpenCV para mostrar um video.\n",
    "\n",
    "Note que para isso, na função `cv2.waitKey()` é preciso passar um valor de tempo em milissegundos. Por exemplo, `cv2.waitKey(1)` vai esperar 1 milissegundo.\n",
    "\n",
    "**Para fechar a janela, é preciso apertar a tecla `ESC`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"cam\")\n",
    "while(True):\n",
    "    val, image = webcam.read()\n",
    "    if val:\n",
    "        cv2.imshow(\"cam\", image)\n",
    "    if cv2.waitKey(1) == 27: # Aguarda 1 ms pela tecla 'ESC'\n",
    "        break\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prática 4.1\n",
    "\n",
    "\n",
    "**Exercício 4.1.1**: Usando a célula abaixo, baixe uma imagem da internet, carregue essa imagem e mostre os seus três canais usando janelas do `OpenCV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercício 4.1.2**: Usando a célula abaixo, mostre o video de sua webcam com as cores \"invertidas\" (RGB em vez de BGR), e com a imagem transposta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
